{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HbAEPyXPxb8"
   },
   "source": [
    "### 1.1 Gather the title and genre of the maximum top 10 movies that each user clicked on regarding the number of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uGyzHIxZHcZx",
    "outputId": "6e4a28fe-a1f3-48fb-e9e7-851e74cb95af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58773</td>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58774</td>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58775</td>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58776</td>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58777</td>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime  duration  \\\n",
       "0       58773  2017-01-01 01:15:09       0.0   \n",
       "1       58774  2017-01-01 13:56:02       0.0   \n",
       "2       58775  2017-01-01 15:17:47   10530.0   \n",
       "3       58776  2017-01-01 16:04:13      49.0   \n",
       "4       58777  2017-01-01 19:16:37       0.0   \n",
       "\n",
       "                                title  \\\n",
       "0  Angus, Thongs and Perfect Snogging   \n",
       "1        The Curse of Sleeping Beauty   \n",
       "2                   London Has Fallen   \n",
       "3                            Vendetta   \n",
       "4     The SpongeBob SquarePants Movie   \n",
       "\n",
       "                                              genres release_date    movie_id  \\\n",
       "0                             Comedy, Drama, Romance   2008-07-25  26bd5987e8   \n",
       "1                 Fantasy, Horror, Mystery, Thriller   2016-06-02  f26ed2675e   \n",
       "2                                   Action, Thriller   2016-03-04  f77e500e7a   \n",
       "3                                      Action, Drama   2015-06-12  c74aec7673   \n",
       "4  Animation, Action, Adventure, Comedy, Family, ...   2004-11-19  a80d6fc2aa   \n",
       "\n",
       "      user_id  \n",
       "0  1dea19f6fe  \n",
       "1  544dcbc510  \n",
       "2  7cbcc791bf  \n",
       "3  ebf43c36b6  \n",
       "4  a57c992287  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "from collections import defaultdict \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "dataset = pd.read_csv(\"vodclickstream_uk_movies_03.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the data, I will change the data type for the following columns: [datetime and release_date] to a pandas date time object. Also, I will check how many null values are present in my dataset. Lastly, I will replace the name of the column \"Unnamed: 0\" with \"session\", as the name makes more sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUNceR6vHxUs",
    "outputId": "cd319b5b-5c4a-4132-8323-1388f8d584dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "datetime            0\n",
      "duration            0\n",
      "title               0\n",
      "genres              0\n",
      "release_date    30304\n",
      "movie_id            0\n",
      "user_id             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset.datetime = pd.to_datetime(dataset.datetime)\n",
    "dataset.release_date = pd.to_datetime(dataset.release_date, errors='coerce')\n",
    "print(dataset.isnull().sum())\n",
    "dataset.rename(columns={'Unnamed: 0': 'session'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 30304 missing values for release_date column. But for our purpose, this won't be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to gather the **title and genre** of the **top 10** movies, with regards to the **number of clicks** per user. To be able to break down the dataset into a form where I can access the top ten movie titles and genres for each user, I will use `groupby()` and `sort_values()` repetitively on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-8F3lEo-ZCh4"
   },
   "outputs": [],
   "source": [
    "user_click_counts = dataset.groupby(['user_id', 'title', 'genres']).size().reset_index(name='click_count')\n",
    "\n",
    "# Sort the movies for each user based on click counts\n",
    "user_click_counts = user_click_counts.sort_values(['user_id', 'click_count'], ascending=[True, False])\n",
    "\n",
    "# Get the top 10 movies for each user\n",
    "top_10_movies_per_user = user_click_counts.groupby('user_id').head(10)\n",
    "\n",
    "# Extract title and genre of the top 10 movies\n",
    "df = top_10_movies_per_user[['user_id', 'title', 'genres', 'click_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>click_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004e2862</td>\n",
       "      <td>Hannibal</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Looper</td>\n",
       "      <td>Action, Drama, Sci-Fi, Thriller</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Frailty</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure, Comedy, Family, Fantasy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Resident Evil</td>\n",
       "      <td>Action, Horror, Sci-Fi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          title                              genres  click_count\n",
       "0  00004e2862       Hannibal              Crime, Drama, Thriller            1\n",
       "6  000052a0a0         Looper     Action, Drama, Sci-Fi, Thriller            9\n",
       "3  000052a0a0        Frailty              Crime, Drama, Thriller            3\n",
       "5  000052a0a0        Jumanji  Adventure, Comedy, Family, Fantasy            3\n",
       "7  000052a0a0  Resident Evil              Action, Horror, Sci-Fi            2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "\n",
    "#### Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket.\n",
    "\n",
    "---\n",
    "\n",
    "##### Important note: You must write your minhash function from scratch. You are not permitted to use any already implemented hash functions. Read the class materials and, if necessary, conduct an internet search. The description of hash functions in the book may be helpful as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, I will define a funtion, name as `get_unique_genres_for_user()`, which will aid in storing **storing** unique genres for each user in the `df` dataframe. I will, again, `groupby()` the `df` dataframe by `user_id` column, select the `genres` column and apply our `get_unique_genres_for_user()` function across the `genres` column. This will output a dataframe, that I have named `user_genres`, which contains two columns: `user_id` and `genres`. `user_id` is a column with, as you will see, unique users and `genres` is a column which has a string of unique genres - concatenated together by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_genres_for_user(group):\n",
    "    # Combine all genres for a user into a single list\n",
    "    all_genres = [genre.split(', ') for genre in group]\n",
    "    # Flatten the list of lists and create a set of unique genres\n",
    "    unique_genres = set([item for sublist in all_genres for item in sublist])\n",
    "    return ', '.join(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "1JAf7DNAX6ng",
    "outputId": "895da86e-341a-4abc-85ae-dca0f961e0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161918, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004e2862</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Action, Comedy, Mystery, Thriller, Horror, Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000090e7c8</td>\n",
       "      <td>Mystery, Thriller, Sci-Fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                             genres\n",
       "0  00004e2862                             Crime, Drama, Thriller\n",
       "1  000052a0a0  Action, Comedy, Mystery, Thriller, Horror, Adv...\n",
       "2  000090e7c8                          Mystery, Thriller, Sci-Fi"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping on user_id, then selection the genres column and applying our function!\n",
    "user_genres = df.groupby('user_id')['genres'].apply(lambda x: get_unique_genres_for_user(x)).reset_index()\n",
    "print(user_genres.shape)\n",
    "user_genres.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now check to verify if all the values are unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161918"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_genres.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the number of unique user_ids matches the size of the dataframe. Lastly, I will just explore one random entry of the genres column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action, Comedy, Mystery, Thriller, Horror, Adventure, Fantasy, Family, Sci-Fi, Crime, Drama, Sport, Music'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_genres.genres[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First stop in our Locality Sensitive Hashing process is: **k-Shingling**, or simply **Shingling**. It is the process of converting a string of text into a set of ‘shingles’. The process is similar to moving a window of length k down our string of text and taking a picture at each step. We collate all of those pictures to create our set of shingles. But for our purpose, we will intake the complete word from the genre column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert genre string to list ~ Shingle for each user.\n",
    "user_genres['genres'] = user_genres['genres'].apply(lambda x: x.split(', '))\n",
    "\n",
    "# Get all unique genres\n",
    "unique_genres = set()\n",
    "for genres in user_genres['genres']:\n",
    "    unique_genres.update(genres)\n",
    "\n",
    "unique_genres = list(unique_genres)\n",
    "unique_genres.sort()\n",
    "\n",
    "# Create a dictionary to map genres to column indices - it will help in one hot encoding later.\n",
    "genre_to_index = {genre: i for i, genre in enumerate(unique_genres)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will build a sparse (one hot encoding matrix), also know as characteristics matrix for our data. Rows are the elements (shingles) and columns will be the User_ids in which they appeared. The entry will be 1 if the element (shingle) is in the column (user_id).\n",
    "\n",
    "I will follow the procedure of the book.\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?id=1n752VizpcQaPKajZNjjfuQHd9MQy5e0W\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 161918)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00004e2862</th>\n",
       "      <th>000052a0a0</th>\n",
       "      <th>000090e7c8</th>\n",
       "      <th>000118a755</th>\n",
       "      <th>000296842d</th>\n",
       "      <th>0002aab109</th>\n",
       "      <th>0002abf14f</th>\n",
       "      <th>0002d1c4b1</th>\n",
       "      <th>000499c2b6</th>\n",
       "      <th>00051f0e1f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Film-Noir</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT AVAILABLE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               00004e2862  000052a0a0  000090e7c8  000118a755  000296842d  \\\n",
       "Action                  0           1           0           0           0   \n",
       "Adventure               0           1           0           0           0   \n",
       "Animation               0           0           0           0           0   \n",
       "Biography               0           0           0           0           0   \n",
       "Comedy                  0           1           0           0           0   \n",
       "Crime                   1           1           0           0           0   \n",
       "Documentary             0           0           0           0           0   \n",
       "Drama                   1           1           0           0           1   \n",
       "Family                  0           1           0           0           0   \n",
       "Fantasy                 0           1           0           0           0   \n",
       "Film-Noir               0           0           0           0           0   \n",
       "History                 0           0           0           0           0   \n",
       "Horror                  0           1           0           1           0   \n",
       "Music                   0           1           0           0           0   \n",
       "Musical                 0           0           0           0           0   \n",
       "Mystery                 0           1           1           0           1   \n",
       "NOT AVAILABLE           0           0           0           1           0   \n",
       "News                    0           0           0           0           0   \n",
       "Reality-TV              0           0           0           0           0   \n",
       "Romance                 0           0           0           0           0   \n",
       "Sci-Fi                  0           1           1           0           1   \n",
       "Short                   0           0           0           0           0   \n",
       "Sport                   0           1           0           0           0   \n",
       "Talk-Show               0           0           0           0           0   \n",
       "Thriller                1           1           1           0           1   \n",
       "War                     0           0           0           0           0   \n",
       "Western                 0           0           0           0           0   \n",
       "\n",
       "               0002aab109  0002abf14f  0002d1c4b1  000499c2b6  00051f0e1f  \n",
       "Action                  0           0           0           0           1  \n",
       "Adventure               0           0           0           1           1  \n",
       "Animation               0           0           0           1           0  \n",
       "Biography               1           0           0           0           0  \n",
       "Comedy                  1           0           1           1           1  \n",
       "Crime                   1           0           0           0           0  \n",
       "Documentary             0           0           0           0           0  \n",
       "Drama                   1           1           0           0           0  \n",
       "Family                  0           0           0           1           0  \n",
       "Fantasy                 0           0           0           1           0  \n",
       "Film-Noir               0           0           0           0           0  \n",
       "History                 0           0           0           0           0  \n",
       "Horror                  0           0           0           0           0  \n",
       "Music                   0           0           0           0           0  \n",
       "Musical                 0           0           0           0           0  \n",
       "Mystery                 0           0           0           0           0  \n",
       "NOT AVAILABLE           0           0           0           0           0  \n",
       "News                    0           0           0           0           0  \n",
       "Reality-TV              0           0           0           0           0  \n",
       "Romance                 0           1           0           0           0  \n",
       "Sci-Fi                  0           0           1           0           1  \n",
       "Short                   0           0           0           0           0  \n",
       "Sport                   0           0           0           0           0  \n",
       "Talk-Show               0           0           0           0           0  \n",
       "Thriller                0           0           0           0           0  \n",
       "War                     0           0           0           0           0  \n",
       "Western                 0           0           0           0           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix representation (one-hot encoding) for users' genres\n",
    "matrix_representation = [] # matrix initialisation \n",
    "for genres in user_genres['genres']: # for each genre_list in user_genres['genres'] column\n",
    "    # Create a row filled with zeros equal to the number of unique genres\n",
    "    row = [0] * len(unique_genres)\n",
    "    for genre in genres: # for each genre in the genres (list)\n",
    "        # Set the index in the row to 1 for genre index is present in genre_to_index dict\n",
    "        row[genre_to_index[genre]] = 1\n",
    "    matrix_representation.append(row)\n",
    "\n",
    "matrix_df = pd.DataFrame(matrix_representation, columns=unique_genres) # initialisation of empty df\n",
    "matrix_df.set_index(user_genres['user_id'], inplace=True) # setting index to the user_id column of our original dataframe\n",
    "matrix_df.index.name = None # to get rid of name when transpose will be applied\n",
    "matrix_df = matrix_df.T # transposing to get the format, as in the book\n",
    "print(matrix_df.shape)\n",
    "matrix_df.iloc[:,:10] # all rows (genres) and first 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minhashing is the next step in our LSH process, allowing us to convert our sparse vectors into dense vectors. But before we can perform minhashing on our sparse vectors, what we do is generate some carefully chosen hash functions that simulate the effect of permuting the entire rows uniquely. Also, the number of hash functions we chose here would reflect the number of rows we want to create in our dense vector/signature. For example, If we want 8 rows in our signature matrix (dense representation), we would use 8 hash functions. At the end of this, we produce our minhash signature — or dense vector.\n",
    "\n",
    "Again, I will be following the algorith provided by the author of the book:\n",
    "\n",
    "---\n",
    "<img src = \"https://drive.google.com/uc?id=1P48autheVmPblZ3k2RrJ97cS_URD0Thu\" width=\"600\" height=\"100\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of: hash functions, unique genres, and hash functions with specific 'a' and 'b' values\n",
    "num_hash_functions = 8\n",
    "num_genres = len(unique_genres)\n",
    "# the values of a and b here are chosen carefully, after much trial and error. they simulate a true permuation.\n",
    "hash_functions = [(82, 15), (4, 95), (1, 3), (29, 18), (95, 14), (7, 7), (70, 12), (76, 55)]\n",
    "\n",
    "# Convert the DataFrame to a NumPy array for faster computations\n",
    "matrix_array = matrix_df.values.astype(int)\n",
    "\n",
    "# Initialize the signature matrix with infinity values\n",
    "# of dimension num_hash_functions * num_of_users\n",
    "signature_matrix = np.full((num_hash_functions, matrix_array.shape[1]), np.inf) \n",
    "\n",
    "for r in range(matrix_array.shape[0]):  # Iterate through rows\n",
    "    for c in range(matrix_array.shape[1]):  # Iterate through columns\n",
    "        if matrix_array[r, c] != 0: # for all non zero value\n",
    "            for i, (a, b) in enumerate(hash_functions):  # Iterate through hash functions\n",
    "                hash_val = ((a * r + b) % num_genres)  # Calculate the hash value\n",
    "                signature_matrix[i, c] = min(signature_matrix[i, c], hash_val) # take the min and plug it in sig matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00004e2862</th>\n",
       "      <th>000052a0a0</th>\n",
       "      <th>000090e7c8</th>\n",
       "      <th>000118a755</th>\n",
       "      <th>000296842d</th>\n",
       "      <th>0002aab109</th>\n",
       "      <th>0002abf14f</th>\n",
       "      <th>0002d1c4b1</th>\n",
       "      <th>000499c2b6</th>\n",
       "      <th>00051f0e1f</th>\n",
       "      <th>...</th>\n",
       "      <th>fffb9ecb47</th>\n",
       "      <th>fffc1d209b</th>\n",
       "      <th>fffd345213</th>\n",
       "      <th>fffd4d1888</th>\n",
       "      <th>fffd6433d2</th>\n",
       "      <th>fffd9bf758</th>\n",
       "      <th>fffe7b777b</th>\n",
       "      <th>fffeac83be</th>\n",
       "      <th>ffff2c5f9e</th>\n",
       "      <th>ffffd36adf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 161918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00004e2862  000052a0a0  000090e7c8  000118a755  000296842d  0002aab109  \\\n",
       "0        12.0         0.0         3.0         0.0         3.0        18.0   \n",
       "1         2.0         2.0         2.0         8.0         2.0         3.0   \n",
       "2         0.0         0.0         0.0        15.0         0.0         6.0   \n",
       "3         1.0         1.0         4.0        15.0         4.0         1.0   \n",
       "4         3.0         1.0         8.0        20.0         4.0         2.0   \n",
       "5         2.0         2.0         4.0        10.0         2.0         1.0   \n",
       "6        11.0         1.0         8.0        15.0         8.0         6.0   \n",
       "7         3.0         1.0         7.0         2.0         7.0         3.0   \n",
       "\n",
       "   0002abf14f  0002d1c4b1  000499c2b6  00051f0e1f  ...  fffb9ecb47  \\\n",
       "0         7.0         8.0        16.0         8.0  ...         3.0   \n",
       "1         9.0         3.0         3.0         3.0  ...         3.0   \n",
       "2        10.0         7.0         4.0         3.0  ...         6.0   \n",
       "3         2.0         4.0         7.0         4.0  ...         1.0   \n",
       "4         4.0        16.0         1.0         1.0  ...         2.0   \n",
       "5         2.0         8.0         8.0         7.0  ...         1.0   \n",
       "6        16.0         8.0         1.0         1.0  ...         0.0   \n",
       "7        14.0         8.0         8.0         1.0  ...         3.0   \n",
       "\n",
       "   fffc1d209b  fffd345213  fffd4d1888  fffd6433d2  fffd9bf758  fffe7b777b  \\\n",
       "0         8.0        16.0         7.0         6.0         3.0         8.0   \n",
       "1         3.0         3.0         2.0         5.0         7.0         2.0   \n",
       "2         2.0         4.0         0.0        21.0         8.0         0.0   \n",
       "3         1.0         7.0         2.0         0.0         1.0         4.0   \n",
       "4         0.0         1.0         4.0        23.0         3.0         4.0   \n",
       "5         0.0         8.0         2.0        25.0         4.0         2.0   \n",
       "6         1.0         1.0        12.0         3.0         0.0         8.0   \n",
       "7         1.0         8.0         1.0        19.0         3.0         9.0   \n",
       "\n",
       "   fffeac83be  ffff2c5f9e  ffffd36adf  \n",
       "0         3.0         3.0        20.0  \n",
       "1         3.0         2.0         7.0  \n",
       "2         1.0         0.0         8.0  \n",
       "3         1.0         3.0         1.0  \n",
       "4         2.0         8.0         3.0  \n",
       "5         1.0         4.0         2.0  \n",
       "6         0.0         0.0        11.0  \n",
       "7         0.0         1.0         3.0  \n",
       "\n",
       "[8 rows x 161918 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_df = pd.DataFrame(data=signature_matrix, columns=matrix_df.columns)\n",
    "signature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be analysed from the result, we have reduced the dimension of the rows from **27*161918** to **8*161918**. But one might ask, why even minhash? Would the similarity perspective be preserved?\n",
    "\n",
    "Surpirsingly, **YES**. There is a remarkable connection between minhashing and Jaccard similarity of the sets that are minhashed. The probability that the minhash function for a random permutation of rows produces the same value for two sets equals the Jaccard similarity of those sets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind LSH is to efficiently group similar items by hashing them multiple times to the same bucket, aiming to minimize dissimilar items ending up in the same bucket. By considering pairs that hash to the same bucket across various hashings as candidates for similarity comparison, LSH reduces computational load. \n",
    "\n",
    "The goal is to optimize true similar pairs hashing to the same bucket while limiting false positives. When using minhash signatures, LSH divides the signature matrix into **bands**. Each **band applies a hash function to vectors of integers, directing them to numerous buckets**. In other words, we want to maximize collisions — although ideally only for similar inputs.\n",
    "\n",
    "The number of bands must follow this equation: n = b x r. Here, n is the total number of rows, which in our case is 8, b is the number of bands one would like to use, and r would be the number of rows within each band. Let's deploy this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#4 bands, 2 rows = 8 rows (total)\n",
    "num_bands = 4  # Define the number of bands\n",
    "rows_per_band = signature_matrix.shape[0] // num_bands  # Define the number of rows per band\n",
    "n_users = signature_matrix.shape[1]  # Number of users/customers\n",
    "\n",
    "# Initialize a dictionary to store buckets\n",
    "buckets = defaultdict(list)\n",
    "\n",
    "# Define a Hashing function based on our minhash value\n",
    "def minhash_based_hashing(signature_values):\n",
    "    # Convert the signature values to a string for hashing\n",
    "    signature_sum = sum(signature_values)\n",
    "    return ((23*signature_sum + 89) % 997) # return the string HASHED\n",
    "\n",
    "\n",
    "# Perform LSH by hashing users into buckets\n",
    "for idx_user, column in enumerate(signature_matrix.T):  # Iterate over columns (users)\n",
    "    for idx_band, band in enumerate(np.split(column, num_bands)):  # Split into bands\n",
    "        # Create keys for the buckets using a tuple of band index and band values\n",
    "        bucket_key = minhash_based_hashing(band.tolist())\n",
    "        buckets[bucket_key].append(idx_user)  # Append the user index to the corresponding bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buckets) # we have 354 distinct buckets!!!\n",
    "\n",
    "# our bucket is a dict defined in a way that the key is the value of the hash function and value is the list \n",
    "# of user_ids that go (hash into) these buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Locality-Sensitive Hashing (LSH)\n",
    "\n",
    "Now that your buckets are ready, it's time to ask a few queries. We will provide you with some user_ids and ask you to recommend at most five movies to the user to watch based on the movies clicked by similar users.\n",
    "\n",
    "To recommend at most five movies given a user_id, use the following procedure:\n",
    "\n",
    "1. Identify the two most similar users to this user.\n",
    "2. If these two users have any movies in common, recommend those movies based on the total number of clicks by these users.\n",
    "3. If there are no more common movies, try to propose the most clicked movies by the most similar user first, followed by the other user.\n",
    "\n",
    "**Example:** assume you've identified user **A** and **B** as the most similar users to a single user, and we have the following records on these users:\n",
    "\n",
    "- User A with 80% similarity\n",
    "- User B with 50% similarity\n",
    "\n",
    "| user | movie title | #clicks |\n",
    "|----------|----------|----------|\n",
    "| A | Wild Child | 20 |\n",
    "| A | Innocence | 10 |\n",
    "| A | Coin Heist | 2 |\n",
    "| B | Innocence | 30 |\n",
    "| B | Coin Heist | 15 |\n",
    "| B | Before I Fall | 30 |\n",
    "| B | Beyond Skyline | 8 |\n",
    "| B | The Amazing Spider-Man | 5 |\n",
    "\n",
    "**Recommended movies** in order:\n",
    "- Innocence\n",
    "- Coin Heist\n",
    "- Wild Child\n",
    "- Before I Fall\n",
    "- Beyond Skyline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1901"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_col = random.randint(1, signature_df.shape[1]) # a random column number\n",
    "query = signature_df.iloc[:,random_col].name # to get the name of the col (user_id)\n",
    "user_id_index = signature_df.columns.get_loc(query) # get the index of the user_id col\n",
    "user_id_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    # Calculate Jaccard similarity between two sets\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def find_two_most_similar_users(user_id, buckets):\n",
    "    # Find the bucket containing the given user\n",
    "    user_buckets = set() # I assume there is a chance that a user is present in more than one bucket, tho it is rare.\n",
    "    for bucket_key, users in buckets.items():\n",
    "        if user_id in users: # if our user (the query) is in the list\n",
    "            user_buckets.update(users) # update the user_buckets with the list of similar users\n",
    "        \n",
    "    if not user_buckets:\n",
    "        return None  # User not found in any bucket\n",
    "\n",
    "    # Calculate similarity of the given user with users in the bucket\n",
    "    similarities = {}\n",
    "# calculate the jaccard_similarity between query and every other user in our bucket/list of similar users\n",
    "    for other_user_id in user_buckets:\n",
    "        if other_user_id != user_id:\n",
    "            user_set = set(signature_matrix[:, user_id])\n",
    "            other_user_set = set(signature_matrix[:, other_user_id])\n",
    "            similarities[other_user_id] = jaccard_similarity(user_set, other_user_set)\n",
    "\n",
    "    # Find the two most similar users\n",
    "    most_similar_users = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "    return most_similar_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(131144, 1.0), (131333, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "most_similar_users = find_two_most_similar_users(user_id_index, buckets)\n",
    "print(most_similar_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret the result? the first value in the tuple is the user_id and the second value is the jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cf644231f2', 'cfb34b3a77']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_users = [user for user, _ in most_similar_users]\n",
    "list_of_scores = [score for _, score in most_similar_users]\n",
    "user_ids = list()\n",
    "for user in list_of_users:\n",
    "    user_ids.append(signature_df.iloc[:,user].name)\n",
    "user_ids # this will help in making the movies dataframe of these users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>click_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf644231f2</td>\n",
       "      <td>The Ballad of Buster Scruggs</td>\n",
       "      <td>Comedy, Drama, Musical, Mystery, Romance, Western</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cfb34b3a77</td>\n",
       "      <td>The Ballad of Buster Scruggs</td>\n",
       "      <td>Comedy, Drama, Musical, Mystery, Romance, Western</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                         title  \\\n",
       "0  cf644231f2  The Ballad of Buster Scruggs   \n",
       "1  cfb34b3a77  The Ballad of Buster Scruggs   \n",
       "\n",
       "                                              genres  click_count  \n",
       "0  Comedy, Drama, Musical, Mystery, Romance, Western            1  \n",
       "1  Comedy, Drama, Musical, Mystery, Romance, Western            1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = df[df[\"user_id\"].isin(user_ids)].reset_index(drop=True)\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these two users have any movies in common, recommend those movies based on the total number of clicks by these users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cf644231f2', 1.0), ('cfb34b3a77', 1.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_similar_users = list()\n",
    "for x,y in zip(user_ids, list_of_scores):\n",
    "    two_similar_users.append((x,y))\n",
    "two_similar_users # simialr to most_similar_users, but with the original user_id and not the col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(movies, two_similar_users):\n",
    "    \"\"\"\n",
    "    Given data of movies, I have to do the following:\n",
    "    initialise a list called: results\n",
    "    First, check if there are some common titles between two users:\n",
    "    for each common title, count the number of clicks by each user and sum it. then, sort the common titles by the sum of the number of clicks by each user and append the name of the title into the list: results.\n",
    "    Then, If there are no more common movies, try to propose the most clicked movies by the most similar user first, followed by the other user. add those result after the results already in the list: results.\n",
    "    then print the first 5 results of the list: result\n",
    "    \"\"\"\n",
    "    # Find common movies\n",
    "    user_ids = [user[0] for user in two_similar_users]\n",
    "    common_movies = set(movies[movies['user_id'] == user_ids[0]]['title']).intersection(\n",
    "        set(movies[movies['user_id'] == user_ids[1]]['title'])\n",
    "    )\n",
    "\n",
    "    # Initialize a set called 'results' to avoid duplicates\n",
    "    results = list()\n",
    "    common_movies_df = pd.DataFrame\n",
    "    if common_movies:\n",
    "        # If there are common movies, recommend those based on the total number of clicks by these users\n",
    "        common_movies_df = movies[movies['title'].isin(common_movies)].groupby('title')['click_count'].sum().reset_index()\n",
    "        common_movies_df = common_movies_df.sort_values(by='click_count', ascending=False)\n",
    "        results.extend(common_movies_df['title'].tolist())\n",
    "\n",
    "    # Propose the most clicked movies by each user\n",
    "    if not common_movies_df.empty:\n",
    "        movies = movies[~movies[\"title\"].isin(common_movies_df['title'].tolist())]\n",
    "    for user_id, _ in two_similar_users: # first user_id is automatically with the largest similarity score\n",
    "        user_movies = movies[movies['user_id'] == user_id].groupby('title')['click_count'].sum().reset_index()\n",
    "        user_movies = user_movies.sort_values(by='click_count', ascending=False)\n",
    "        results.extend(user_movies['title'].tolist())\n",
    "\n",
    "    # Return the recommended movie titles\n",
    "    return list(results)[:5]  # Return the first 5 unique results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Ballad of Buster Scruggs']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_movies(movies, two_similar_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: `https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/`and Mining of Massive Datasets Book."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
